{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH4nP5Kz4VkX"
   },
   "source": [
    "# LPFormer: An Adaptive Graph Transformer for Link Prediction\n",
    "\n",
    "This notebook implements the LPFormer model as described in the paper \"LPFormer: An Adaptive Graph Transformer for Link Prediction\" (Shomer et al., 2024), applied to the Marvel Universe dataset. The implementation includes all components described in the paper:\n",
    "\n",
    "1. GCN-based node representation learning\n",
    "2. PPR-based relative positional encodings with order invariance\n",
    "3. GATv2 attention mechanism for adaptive pairwise encoding\n",
    "4. Efficient node selection via PPR thresholding using Andersen's algorithm\n",
    "5. Proper evaluation metrics as specified in the paper\n",
    "6. LP factor analysis for performance evaluation\n",
    "\n",
    "The implementation is optimized for GPU execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up7Kp08y4VkY"
   },
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRhz_UBt4yOu",
    "outputId": "767b0c33-9bac-4381-a31c-7d0637717afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from triton==3.3.0->torch) (68.2.2)\n",
      "Requirement already satisfied: numpy in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
      "Requirement already satisfied: pyg-lib in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (0.4.0+pt20cu118)\n",
      "Requirement already satisfied: torch-scatter in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (2.1.2+pt20cu118)\n",
      "Requirement already satisfied: torch-sparse in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (0.6.18+pt20cu118)\n",
      "Requirement already satisfied: torch-cluster in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (1.6.3+pt20cu118)\n",
      "Requirement already satisfied: torch-spline-conv in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (1.2.2+pt20cu118)\n",
      "Requirement already satisfied: scipy in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-sparse) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from scipy->torch-sparse) (1.23.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-geometric in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: fsspec in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->torch-geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /storage/homefs/fn24z071/.local/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: scipy in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: matplotlib in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: networkx in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (3.1)\n",
      "Requirement already satisfied: tqdm in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /software.9/software/Anaconda3/2024.02-1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install core PyTorch (with CUDA 11.8)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install PyTorch Geometric and dependencies for CUDA 11.8\n",
    "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install torch-geometric\n",
    "\n",
    "# Install other required packages\n",
    "!pip install numpy pandas scipy matplotlib networkx tqdm scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0MQzOnZ4VkY",
    "outputId": "c6bc0333-1f2d-4699-de4c-3c6cb3c0c7d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /storage/homefs/fn24z071/.local/lib/python3.11/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv\n",
    "from torch_geometric.utils import to_undirected, add_self_loops, degree\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import norm as sparse_norm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device for GPU acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4-c1l8z4VkZ"
   },
   "source": [
    "## 2. Marvel Dataset Loading and Processing\n",
    "\n",
    "We load and process the Marvel Universe dataset, which consists of connections between heroes and comics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "xgsof6md4VkZ",
    "outputId": "5f9c7024-47d6-44f8-9a2f-d5d0a39aab4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Marvel dataset...\n",
      "Dataset loaded in 0.09 seconds\n",
      "Edges shape: (96104, 2)\n",
      "Nodes shape: (19090, 2)\n",
      "\n",
      "Edges preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hero</th>\n",
       "      <th>comic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24-HOUR MAN/EMMANUEL</td>\n",
       "      <td>AA2 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>AVF 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>AVF 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>COC 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>H2 251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hero   comic\n",
       "0  24-HOUR MAN/EMMANUEL  AA2 35\n",
       "1  3-D MAN/CHARLES CHAN   AVF 4\n",
       "2  3-D MAN/CHARLES CHAN   AVF 5\n",
       "3  3-D MAN/CHARLES CHAN   COC 1\n",
       "4  3-D MAN/CHARLES CHAN  H2 251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nodes preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001 10</td>\n",
       "      <td>comic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001 8</td>\n",
       "      <td>comic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001 9</td>\n",
       "      <td>comic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24-HOUR MAN/EMMANUEL</td>\n",
       "      <td>hero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-D MAN/CHARLES CHAN</td>\n",
       "      <td>hero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   node   type\n",
       "0               2001 10  comic\n",
       "1                2001 8  comic\n",
       "2                2001 9  comic\n",
       "3  24-HOUR MAN/EMMANUEL   hero\n",
       "4  3-D MAN/CHARLES CHAN   hero"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in edges: 0\n",
      "Missing values in nodes: 0\n",
      "\n",
      "Unique heroes: 6439\n",
      "Unique comics: 12651\n",
      "Node types: ['comic' 'hero']\n",
      "Node type counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "comic    12651\n",
       "hero      6439\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading Marvel dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Marvel dataset\n",
    "edges_df = pd.read_csv('edges_corr.csv')\n",
    "nodes_df = pd.read_csv('nodes_corr.csv')\n",
    "\n",
    "print(f\"Dataset loaded in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"Edges shape: {edges_df.shape}\")\n",
    "print(f\"Nodes shape: {nodes_df.shape}\")\n",
    "\n",
    "# Display first few rows of each dataset\n",
    "print(\"\\nEdges preview:\")\n",
    "display(edges_df.head())\n",
    "\n",
    "print(\"\\nNodes preview:\")\n",
    "display(nodes_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in edges:\", edges_df.isnull().sum().sum())\n",
    "print(\"Missing values in nodes:\", nodes_df.isnull().sum().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nUnique heroes:\", edges_df['hero'].nunique())\n",
    "print(\"Unique comics:\", edges_df['comic'].nunique())\n",
    "print(\"Node types:\", nodes_df['type'].unique())\n",
    "print(\"Node type counts:\")\n",
    "display(nodes_df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy5-Hnwn4VkZ",
    "outputId": "c9a5a5a5-e9c3-4e9a-a2e5-e2e1e1e9c5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Marvel dataset...\n",
      "Warning: Found 277 heroes and 0 comics missing from nodes_df\n",
      "Dataset processing completed in 0.15 seconds\n",
      "Node feature shape: torch.Size([19090, 3])\n",
      "Edge index shape: torch.Size([2, 191654])\n",
      "Number of nodes: 19090\n",
      "Number of edges: 191654\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Marvel dataset...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Encode node IDs to indices\n",
    "node_encoder = LabelEncoder()\n",
    "nodes_df['node_idx'] = node_encoder.fit_transform(nodes_df['node'])\n",
    "\n",
    "# Create a mapping from node names to indices\n",
    "node_to_idx = {node: idx for node, idx in zip(nodes_df['node'], nodes_df['node_idx'])}\n",
    "idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
    "\n",
    "# Map edges to node indices\n",
    "edges_df['hero_idx'] = edges_df['hero'].map(node_to_idx)\n",
    "edges_df['comic_idx'] = edges_df['comic'].map(node_to_idx)\n",
    "\n",
    "# Check for mapping failures (NaN values)\n",
    "missing_heroes = edges_df[edges_df['hero'].map(lambda x: x not in node_to_idx)]\n",
    "missing_comics = edges_df[edges_df['comic'].map(lambda x: x not in node_to_idx)]\n",
    "\n",
    "if len(missing_heroes) > 0 or len(missing_comics) > 0:\n",
    "    print(f\"Warning: Found {len(missing_heroes)} heroes and {len(missing_comics)} comics missing from nodes_df\")\n",
    "    # Filter out edges with missing nodes\n",
    "    edges_df = edges_df[edges_df['hero'].map(lambda x: x in node_to_idx) & \n",
    "                        edges_df['comic'].map(lambda x: x in node_to_idx)]\n",
    "    # Recalculate indices\n",
    "    edges_df['hero_idx'] = edges_df['hero'].map(node_to_idx)\n",
    "    edges_df['comic_idx'] = edges_df['comic'].map(node_to_idx)\n",
    "\n",
    "# Create edge index tensor\n",
    "edge_index = torch.tensor([edges_df['hero_idx'].values.astype(np.int64), \n",
    "                          edges_df['comic_idx'].values.astype(np.int64)], dtype=torch.long)\n",
    "\n",
    "# Make the graph undirected for link prediction\n",
    "edge_index = to_undirected(edge_index)\n",
    "\n",
    "# Create node type encoding\n",
    "nodes_df['type_idx'] = nodes_df['type'].map({'hero': 0, 'comic': 1})\n",
    "node_types = torch.tensor(nodes_df['type_idx'].values, dtype=torch.long)\n",
    "\n",
    "# Create node features\n",
    "# 1. One-hot encoding for node type\n",
    "type_features = F.one_hot(node_types, num_classes=2).float()\n",
    "\n",
    "# 2. Add degree features (normalized)\n",
    "row, col = edge_index\n",
    "deg = degree(row, nodes_df.shape[0])\n",
    "deg_normalized = deg / deg.max()\n",
    "deg_features = deg_normalized.unsqueeze(1)\n",
    "\n",
    "# Combine features\n",
    "node_features = torch.cat([type_features, deg_features], dim=1)\n",
    "\n",
    "# Create PyG Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "data.num_nodes = nodes_df.shape[0]\n",
    "\n",
    "print(f\"Dataset processing completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Display results\n",
    "print(f\"Node feature shape: {node_features.shape}\")\n",
    "print(f\"Edge index shape: {edge_index.shape}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.edge_index.size(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Uw_Yx5G4VkZ",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation/test splits...\n",
      "Data splits created in 0.48 seconds\n",
      "Train positive edges: 76663\n",
      "Train negative edges: 76663\n",
      "Validation positive edges: 9582\n",
      "Validation negative edges: 9582\n",
      "Test positive edges: 9582\n",
      "Test negative edges: 9582\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating train/validation/test splits...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create train/validation/test splits\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1.0\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# Move to GPU (or CPU fallback)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Create split_edge dictionary\n",
    "split_edge = {\n",
    "    'train': {\n",
    "        'edge': train_data.edge_label_index[:, train_data.edge_label == 1].t(),\n",
    "        'edge_neg': train_data.edge_label_index[:, train_data.edge_label == 0].t()\n",
    "    },\n",
    "    'valid': {\n",
    "        'edge': val_data.edge_label_index[:, val_data.edge_label == 1].t(),\n",
    "        'edge_neg': val_data.edge_label_index[:, val_data.edge_label == 0].t()\n",
    "    },\n",
    "    'test': {\n",
    "        'edge': test_data.edge_label_index[:, test_data.edge_label == 1].t(),\n",
    "        'edge_neg': test_data.edge_label_index[:, test_data.edge_label == 0].t()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Data splits created in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print split statistics\n",
    "print(f\"Train positive edges: {len(split_edge['train']['edge'])}\")\n",
    "print(f\"Train negative edges: {len(split_edge['train']['edge_neg'])}\")\n",
    "print(f\"Validation positive edges: {len(split_edge['valid']['edge'])}\")\n",
    "print(f\"Validation negative edges: {len(split_edge['valid']['edge_neg'])}\")\n",
    "print(f\"Test positive edges: {len(split_edge['test']['edge'])}\")\n",
    "print(f\"Test negative edges: {len(split_edge['test']['edge_neg'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbSvAonN4Vka"
   },
   "source": [
    "## 3. PPR Computation using Andersen's Algorithm\n",
    "\n",
    "We implement the efficient Personalized PageRank (PPR) computation using Andersen's algorithm as mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zvHOjips4Vka"
   },
   "outputs": [],
   "source": [
    "def compute_ppr_andersen(edge_index, alpha=0.15, eps=1e-5, num_nodes=None):\n",
    "    \"\"\"\n",
    "    Compute Personalized PageRank (PPR) matrix using Andersen's algorithm.\n",
    "\n",
    "    Args:\n",
    "        edge_index: Edge index tensor [2, num_edges]\n",
    "        alpha: Teleportation probability (default: 0.15)\n",
    "        eps: Error tolerance (default: 1e-5)\n",
    "        num_nodes: Number of nodes in the graph (optional)\n",
    "\n",
    "    Returns:\n",
    "        PPR matrix as a torch tensor [num_nodes, num_nodes]\n",
    "    \"\"\"\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max().item() + 1\n",
    "\n",
    "    print(f\"Computing PPR matrix for {num_nodes} nodes using Andersen's algorithm...\")\n",
    "    print(f\"This may take a while for large graphs. Please be patient.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Convert edge_index to scipy sparse matrix\n",
    "    edge_list = edge_index.t().cpu().numpy()\n",
    "    adj = sp.coo_matrix(\n",
    "        (np.ones(edge_list.shape[0]), (edge_list[:, 0], edge_list[:, 1])),\n",
    "        shape=(num_nodes, num_nodes),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Make the adjacency matrix symmetric (undirected)\n",
    "    adj = adj + adj.T\n",
    "    adj = adj.tocsr()\n",
    "\n",
    "    # Normalize the adjacency matrix by row\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    rowsum[rowsum == 0] = 1.0  # Avoid division by zero\n",
    "    d_inv = np.power(rowsum, -1).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.0\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    norm_adj = d_mat_inv.dot(adj)\n",
    "\n",
    "    # Initialize PPR matrix\n",
    "    ppr_matrix = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "\n",
    "    # Progress tracking variables\n",
    "    last_update_time = time.time()\n",
    "    update_interval = 5  # seconds\n",
    "\n",
    "    # Compute PPR for each node using Andersen's algorithm\n",
    "    for i in tqdm(range(num_nodes), desc=\"Computing PPR\"):\n",
    "        # Print progress update every few seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - last_update_time > update_interval:\n",
    "            elapsed = current_time - start_time\n",
    "            progress = (i + 1) / num_nodes\n",
    "            eta = elapsed / progress - elapsed if progress > 0 else 0\n",
    "            print(f\"Progress: {progress*100:.1f}% ({i+1}/{num_nodes}), Elapsed: {elapsed:.1f}s, ETA: {eta:.1f}s\")\n",
    "            last_update_time = current_time\n",
    "            \n",
    "        # Initialize residual and approximation vectors\n",
    "        r = np.zeros(num_nodes)\n",
    "        p = np.zeros(num_nodes)\n",
    "        r[i] = 1.0\n",
    "\n",
    "        # Push operation\n",
    "        while np.max(r) > eps:\n",
    "            # Find node with highest residual\n",
    "            j = np.argmax(r)\n",
    "\n",
    "            # Update approximation and residual\n",
    "            p[j] += alpha * r[j]\n",
    "\n",
    "            # Push residual to neighbors\n",
    "            neighbors = norm_adj[j].nonzero()[1]\n",
    "            if len(neighbors) > 0:  # Check if node has neighbors\n",
    "                for k in neighbors:\n",
    "                    r[k] += (1 - alpha) * r[j] * norm_adj[j, k] / len(neighbors)\n",
    "\n",
    "            # Reset residual\n",
    "            r[j] = 0\n",
    "\n",
    "        # Store PPR vector for node i\n",
    "        ppr_matrix[i] = p\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    ppr_tensor = torch.FloatTensor(ppr_matrix)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"PPR matrix computation completed in {total_time:.2f} seconds!\")\n",
    "    return ppr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT0w4gAq4Vka"
   },
   "source": [
    "## 4. LPFormer Model Implementation\n",
    "\n",
    "We implement the LPFormer model with all components as described in the paper, including GATv2 attention and order-invariant RPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DDtc5aPu4Vka"
   },
   "outputs": [],
   "source": [
    "class PPRThresholding(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for PPR-based thresholding to select nodes to attend to.\n",
    "    Implements Equation (10) from the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, ppr_matrix, cn_threshold=0.01, one_hop_threshold=0.001, multi_hop_threshold=0.0001):\n",
    "        super(PPRThresholding, self).__init__()\n",
    "        self.ppr_matrix = ppr_matrix\n",
    "        self.cn_threshold = cn_threshold\n",
    "        self.one_hop_threshold = one_hop_threshold\n",
    "        self.multi_hop_threshold = multi_hop_threshold\n",
    "        self.device = ppr_matrix.device\n",
    "\n",
    "    def forward(self, a, b, adj_matrix):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            a, b: Indices of the two nodes in the target link\n",
    "            adj_matrix: Adjacency matrix [num_nodes, num_nodes]\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of filtered nodes by type (CN, 1-hop, >1-hop)\n",
    "        \"\"\"\n",
    "        # Ensure indices are on the same device as the PPR matrix\n",
    "        a = a.to(self.ppr_matrix.device)\n",
    "        b = b.to(self.ppr_matrix.device)\n",
    "        adj_matrix = adj_matrix.to(self.ppr_matrix.device)\n",
    "        \n",
    "        # Identify common neighbors (CN)\n",
    "        cn_mask = (adj_matrix[a] == 1) & (adj_matrix[b] == 1)\n",
    "        cn_nodes = torch.where(cn_mask)[0].to(self.ppr_matrix.device)\n",
    "\n",
    "        # Identify 1-hop neighbors (connected to either a or b, but not both)\n",
    "        one_hop_mask = ((adj_matrix[a] == 1) | (adj_matrix[b] == 1)) & (~cn_mask)\n",
    "        one_hop_nodes = torch.where(one_hop_mask)[0].to(self.ppr_matrix.device)\n",
    "\n",
    "        # Identify multi-hop neighbors (not connected to either a or b)\n",
    "        multi_hop_mask = (adj_matrix[a] == 0) & (adj_matrix[b] == 0)\n",
    "        multi_hop_mask[a] = False  # Exclude a and b\n",
    "        multi_hop_mask[b] = False\n",
    "        multi_hop_nodes = torch.where(multi_hop_mask)[0].to(self.ppr_matrix.device)\n",
    "\n",
    "        # Apply PPR thresholding as per Equation (10)\n",
    "        if len(cn_nodes) > 0:\n",
    "            filtered_cn = cn_nodes[\n",
    "                (self.ppr_matrix[a, cn_nodes] > self.cn_threshold) &\n",
    "                (self.ppr_matrix[b, cn_nodes] > self.cn_threshold)\n",
    "            ]\n",
    "        else:\n",
    "            filtered_cn = torch.tensor([], dtype=torch.long, device=self.ppr_matrix.device)\n",
    "        \n",
    "        if len(one_hop_nodes) > 0:\n",
    "            filtered_one_hop = one_hop_nodes[\n",
    "                (self.ppr_matrix[a, one_hop_nodes] > self.one_hop_threshold) |\n",
    "                (self.ppr_matrix[b, one_hop_nodes] > self.one_hop_threshold)\n",
    "            ]\n",
    "        else:\n",
    "            filtered_one_hop = torch.tensor([], dtype=torch.long, device=self.ppr_matrix.device)\n",
    "        \n",
    "        if len(multi_hop_nodes) > 0:\n",
    "            filtered_multi_hop = multi_hop_nodes[\n",
    "                (self.ppr_matrix[a, multi_hop_nodes] > self.multi_hop_threshold) |\n",
    "                (self.ppr_matrix[b, multi_hop_nodes] > self.multi_hop_threshold)\n",
    "            ]\n",
    "        else:\n",
    "            filtered_multi_hop = torch.tensor([], dtype=torch.long, device=self.ppr_matrix.device)\n",
    "\n",
    "        return {\n",
    "            'cn': filtered_cn,\n",
    "            'one_hop': filtered_one_hop,\n",
    "            'multi_hop': filtered_multi_hop\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r93Kq7Dk4Vkb"
   },
   "outputs": [],
   "source": [
    "class PPRPositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for PPR-based relative positional encoding with order invariance.\n",
    "    Implements Equations (7) and (8) from the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, ppr_matrix, hidden_dim):\n",
    "        super(PPRPositionalEncoding, self).__init__()\n",
    "        self.ppr_matrix = ppr_matrix\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = ppr_matrix.device\n",
    "\n",
    "        # Separate MLPs for different node types as mentioned in the paper\n",
    "        self.cn_mlp = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.one_hop_mlp = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.multi_hop_mlp = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b, nodes, node_types):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            a, b: Indices of the two nodes in the target link\n",
    "            nodes: Tensor of node indices to compute RPE for\n",
    "            node_types: List of node types ('cn', 'one_hop', 'multi_hop')\n",
    "\n",
    "        Returns:\n",
    "            Tensor of relative positional encodings [num_nodes, hidden_dim]\n",
    "        \"\"\"\n",
    "        # Ensure indices are on the same device as the PPR matrix\n",
    "        a = a.to(self.ppr_matrix.device)\n",
    "        b = b.to(self.ppr_matrix.device)\n",
    "        nodes = nodes.to(self.ppr_matrix.device)\n",
    "        \n",
    "        rpes = []\n",
    "\n",
    "        for i, node in enumerate(nodes):\n",
    "            # Get PPR scores\n",
    "            node = node.to(self.ppr_matrix.device)\n",
    "            ppr_a_u = self.ppr_matrix[a, node].item()\n",
    "            ppr_b_u = self.ppr_matrix[b, node].item()\n",
    "\n",
    "            # Create PPR feature vector\n",
    "            ppr_features_ab = torch.tensor([ppr_a_u, ppr_b_u], dtype=torch.float32, device=self.ppr_matrix.device)\n",
    "            ppr_features_ba = torch.tensor([ppr_b_u, ppr_a_u], dtype=torch.float32, device=self.ppr_matrix.device)\n",
    "\n",
    "            # Apply appropriate MLP based on node type\n",
    "            node_type = node_types[i]\n",
    "            if node_type == 'cn':\n",
    "                # Implement order invariance as per Equation (8)\n",
    "                rpe_ab = self.cn_mlp(ppr_features_ab)\n",
    "                rpe_ba = self.cn_mlp(ppr_features_ba)\n",
    "                rpe = rpe_ab + rpe_ba\n",
    "            elif node_type == 'one_hop':\n",
    "                # Implement order invariance as per Equation (8)\n",
    "                rpe_ab = self.one_hop_mlp(ppr_features_ab)\n",
    "                rpe_ba = self.one_hop_mlp(ppr_features_ba)\n",
    "                rpe = rpe_ab + rpe_ba\n",
    "            else:  # multi_hop\n",
    "                # Implement order invariance as per Equation (8)\n",
    "                rpe_ab = self.multi_hop_mlp(ppr_features_ab)\n",
    "                rpe_ba = self.multi_hop_mlp(ppr_features_ba)\n",
    "                rpe = rpe_ab + rpe_ba\n",
    "\n",
    "            rpes.append(rpe)\n",
    "\n",
    "        if len(rpes) > 0:\n",
    "            return torch.stack(rpes)\n",
    "        else:\n",
    "            return torch.tensor([], dtype=torch.float32, device=self.ppr_matrix.device).reshape(0, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9Vu0K_1m4Vkb"
   },
   "outputs": [],
   "source": [
    "class GATv2AttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    GATv2-based attention layer for LPFormer.\n",
    "    Implements the attention mechanism described in Equations (4) and (5).\n",
    "    \"\"\"\n",
    "    def __init__(self, query_dim, key_dim, num_heads=4, dropout=0.1):\n",
    "        super(GATv2AttentionLayer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_dim = query_dim\n",
    "        self.head_dim = query_dim // num_heads\n",
    "        assert self.head_dim * num_heads == query_dim, \"hidden_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(query_dim * 2, query_dim)  # *2 for concatenated nodes a and b\n",
    "        self.k_proj = nn.Linear(key_dim * 2, query_dim)    # *2 for node features + RPE\n",
    "        self.v_proj = nn.Linear(key_dim * 2, query_dim)    # *2 for node features + RPE\n",
    "\n",
    "        # GATv2 attention mechanism\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(self.head_dim * 2, self.head_dim),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Linear(self.head_dim, 1)\n",
    "        )\n",
    "\n",
    "        self.out_proj = nn.Linear(query_dim, query_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query_nodes, key_nodes, rpe, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query_nodes: Features of nodes a and b [2, hidden_dim]\n",
    "            key_nodes: Features of nodes to attend to [num_nodes, hidden_dim]\n",
    "            rpe: Relative positional encodings [num_nodes, hidden_dim]\n",
    "            mask: Attention mask (optional)\n",
    "\n",
    "        Returns:\n",
    "            Attention output [1, hidden_dim]\n",
    "        \"\"\"\n",
    "        # Handle empty key_nodes case\n",
    "        if key_nodes.shape[0] == 0:\n",
    "            return torch.zeros(1, self.hidden_dim, device=query_nodes.device)\n",
    "            \n",
    "        batch_size = 1  # For a single link\n",
    "        num_nodes = key_nodes.shape[0]\n",
    "\n",
    "        # Create query from concatenated features of nodes a and b\n",
    "        q = self.q_proj(query_nodes.view(batch_size, -1))  # [1, hidden_dim]\n",
    "\n",
    "        # Create keys and values with RPE\n",
    "        k = self.k_proj(torch.cat([key_nodes, rpe], dim=1))  # [num_nodes, hidden_dim]\n",
    "        v = self.v_proj(torch.cat([key_nodes, rpe], dim=1))  # [num_nodes, hidden_dim]\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        q = q.view(batch_size, self.num_heads, self.head_dim)  # [1, num_heads, head_dim]\n",
    "        k = k.view(num_nodes, self.num_heads, self.head_dim)   # [num_nodes, num_heads, head_dim]\n",
    "        v = v.view(num_nodes, self.num_heads, self.head_dim)   # [num_nodes, num_heads, head_dim]\n",
    "\n",
    "        # Compute GATv2 attention scores\n",
    "        attn_scores = []\n",
    "        for h in range(self.num_heads):\n",
    "            q_h = q[:, h, :]  # [1, head_dim]\n",
    "            k_h = k[:, h, :]  # [num_nodes, head_dim]\n",
    "\n",
    "            # Repeat query for each node\n",
    "            q_expanded = q_h.repeat(num_nodes, 1)  # [num_nodes, head_dim]\n",
    "\n",
    "            # Concatenate query and key for each node\n",
    "            qk_concat = torch.cat([q_expanded, k_h], dim=1)  # [num_nodes, 2*head_dim]\n",
    "\n",
    "            # Apply GATv2 attention mechanism\n",
    "            scores_h = self.attn(qk_concat).squeeze(-1)  # [num_nodes]\n",
    "            attn_scores.append(scores_h)\n",
    "\n",
    "        # Stack attention scores\n",
    "        attn_scores = torch.stack(attn_scores, dim=1)  # [num_nodes, num_heads]\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask.unsqueeze(1) == 0, -1e9)\n",
    "\n",
    "        # Apply softmax and dropout\n",
    "        attn_weights = F.softmax(attn_scores, dim=0)  # [num_nodes, num_heads]\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Compute weighted sum\n",
    "        attn_output = torch.zeros(batch_size, self.num_heads, self.head_dim, device=query_nodes.device)\n",
    "        for h in range(self.num_heads):\n",
    "            v_h = v[:, h, :]  # [num_nodes, head_dim]\n",
    "            weights_h = attn_weights[:, h].unsqueeze(1)  # [num_nodes, 1]\n",
    "            output_h = (v_h * weights_h).sum(dim=0, keepdim=True)  # [1, head_dim]\n",
    "            attn_output[:, h, :] = output_h\n",
    "\n",
    "        # Reshape and apply output projection\n",
    "        attn_output = attn_output.view(batch_size, -1)  # [1, hidden_dim]\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Gg1Ue-Uy4Vkb"
   },
   "outputs": [],
   "source": [
    "class LPFormer(nn.Module):\n",
    "    \"\"\"\n",
    "    LPFormer model for link prediction as described in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, node_features, edge_index, hidden_dim=64, num_layers=2, \n",
    "                 num_heads=4, dropout=0.1, ppr_threshold=1e-3):\n",
    "        super(LPFormer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.num_nodes = num_nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        print(f\"\\n----- Initializing LPFormer Model -----\")\n",
    "        print(f\"Number of nodes: {num_nodes}\")\n",
    "        print(f\"Hidden dimension: {hidden_dim}\")\n",
    "        print(f\"Number of layers: {num_layers}\")\n",
    "        print(f\"Number of attention heads: {num_heads}\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Node feature dimensions\n",
    "        self.node_dim = node_features.shape[1]\n",
    "        print(f\"Node feature dimension: {self.node_dim}\")\n",
    "\n",
    "        # GCN for node representation\n",
    "        print(\"Creating GCN layers for node representation...\")\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(self.node_dim, hidden_dim))\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "            print(f\"  Added GCN layer {i+1} with hidden_dim {hidden_dim}\")\n",
    "\n",
    "        # Compute PPR matrix using Andersen's algorithm\n",
    "        print(\"Computing PPR matrix using Andersen's algorithm...\")\n",
    "        ppr_tensor = compute_ppr_andersen(\n",
    "            edge_index, \n",
    "            alpha=0.15, \n",
    "            eps=1e-5, \n",
    "            num_nodes=num_nodes\n",
    "        )\n",
    "        # Move PPR matrix to the correct device\n",
    "        ppr_tensor = ppr_tensor.to(self.device)\n",
    "        self.register_buffer('ppr_matrix', ppr_tensor)\n",
    "        print(f\"PPR matrix shape: {ppr_tensor.shape}, device: {ppr_tensor.device}\")\n",
    "\n",
    "        # Create adjacency matrix\n",
    "        print(\"Creating adjacency matrix...\")\n",
    "        edge_list = edge_index.t().cpu().numpy()\n",
    "        adj = sp.coo_matrix(\n",
    "            (np.ones(edge_list.shape[0]), (edge_list[:, 0], edge_list[:, 1])),\n",
    "            shape=(num_nodes, num_nodes),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        adj_tensor = torch.FloatTensor(adj.todense()).to(self.device)\n",
    "        self.register_buffer('adj_matrix', adj_tensor)\n",
    "        print(f\"Adjacency matrix shape: {adj_tensor.shape}, device: {adj_tensor.device}\")\n",
    "\n",
    "        # PPR thresholding module\n",
    "        print(\"Creating PPR thresholding module...\")\n",
    "        cn_threshold = ppr_threshold\n",
    "        one_hop_threshold = ppr_threshold / 10\n",
    "        multi_hop_threshold = ppr_threshold / 100\n",
    "        self.ppr_threshold = PPRThresholding(\n",
    "            self.ppr_matrix, \n",
    "            cn_threshold=cn_threshold,\n",
    "            one_hop_threshold=one_hop_threshold,\n",
    "            multi_hop_threshold=multi_hop_threshold\n",
    "        )\n",
    "\n",
    "        # PPR positional encoding with order invariance\n",
    "        print(\"Creating PPR positional encoding module with order invariance...\")\n",
    "        self.ppr_pos_encoding = PPRPositionalEncoding(self.ppr_matrix, hidden_dim)\n",
    "\n",
    "        # GATv2 attention layers\n",
    "        print(\"Creating GATv2 attention layers...\")\n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.attention_layers.append(GATv2AttentionLayer(hidden_dim, hidden_dim, num_heads, dropout))\n",
    "            print(f\"  Added GATv2 attention layer {i+1}\")\n",
    "\n",
    "        # Final prediction layer\n",
    "        print(\"Creating final prediction layer...\")\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 3, hidden_dim),  # node product + pairwise + 3 counts\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        print(\"LPFormer model initialized successfully!\")\n",
    "        print(\"-----------------------------------------\\n\")\n",
    "\n",
    "    def forward(self, node_features, edge_index, target_links):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node_features: Node features [num_nodes, node_dim]\n",
    "            edge_index: Edge index [2, num_edges]\n",
    "            target_links: Target links to predict [num_links, 2]\n",
    "\n",
    "        Returns:\n",
    "            Predictions for target links [num_links]\n",
    "        \"\"\"\n",
    "        # Move inputs to the same device as model\n",
    "        node_features = node_features.to(self.device)\n",
    "        edge_index = edge_index.to(self.device)\n",
    "        target_links = target_links.to(self.device)\n",
    "\n",
    "        # Node representation via GCN\n",
    "        x = node_features\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:  # Apply ReLU to all but the last layer\n",
    "                x = F.relu(x)\n",
    "\n",
    "        # Predict for each target link\n",
    "        predictions = []\n",
    "        \n",
    "        # Progress tracking variables\n",
    "        total_links = len(target_links)\n",
    "        progress_interval = max(1, total_links // 10)  # Show progress every 10%\n",
    "        \n",
    "        for i, link in enumerate(target_links):\n",
    "            # Show progress for large batches\n",
    "            #if total_links > 100 and i % progress_interval == 0:\n",
    "            #    print(f\"Processing links: {i}/{total_links} ({i/total_links*100:.1f}%)\")\n",
    "                \n",
    "            a, b = link\n",
    "            \n",
    "            # Ensure a and b are on the correct device\n",
    "            a = a.to(self.device)\n",
    "            b = b.to(self.device)\n",
    "\n",
    "            # Get nodes to attend to via PPR thresholding\n",
    "            filtered_nodes = self.ppr_threshold(a, b, self.adj_matrix)\n",
    "\n",
    "            # Combine all filtered nodes\n",
    "            nodes_list = [filtered_nodes['cn'], filtered_nodes['one_hop'], filtered_nodes['multi_hop']]\n",
    "            non_empty_nodes = [nodes for nodes in nodes_list if len(nodes) > 0]\n",
    "            \n",
    "            if len(non_empty_nodes) > 0:\n",
    "                nodes_to_attend = torch.cat(non_empty_nodes, dim=0)\n",
    "            else:\n",
    "                nodes_to_attend = torch.tensor([], dtype=torch.long, device=self.device)\n",
    "\n",
    "            if len(nodes_to_attend) == 0:\n",
    "                # If no nodes to attend to, use the direct product of node representations\n",
    "                node_product = x[a] * x[b]\n",
    "                predictions.append(self.predictor(torch.cat([\n",
    "                    node_product, \n",
    "                    torch.zeros(self.hidden_dim, device=self.device),\n",
    "                    torch.zeros(3, device=self.device)\n",
    "                ])))\n",
    "                continue\n",
    "\n",
    "            # Create node type indicators\n",
    "            node_types = []\n",
    "            for node in nodes_to_attend:\n",
    "                if node in filtered_nodes['cn']:\n",
    "                    node_types.append('cn')\n",
    "                elif node in filtered_nodes['one_hop']:\n",
    "                    node_types.append('one_hop')\n",
    "                else:\n",
    "                    node_types.append('multi_hop')\n",
    "\n",
    "            # Get RPE for each node with order invariance\n",
    "            rpe = self.ppr_pos_encoding(a, b, nodes_to_attend, node_types)\n",
    "\n",
    "            # Apply GATv2 attention mechanism\n",
    "            query_nodes = torch.stack([x[a], x[b]])\n",
    "            key_nodes = x[nodes_to_attend]\n",
    "\n",
    "            pairwise_encoding = None\n",
    "            for j, attn_layer in enumerate(self.attention_layers):\n",
    "                if pairwise_encoding is None:\n",
    "                    pairwise_encoding = attn_layer(query_nodes, key_nodes, rpe)\n",
    "                else:\n",
    "                    pairwise_encoding = attn_layer(query_nodes, key_nodes, rpe) + pairwise_encoding\n",
    "\n",
    "            # Element-wise product of node representations\n",
    "            node_product = x[a] * x[b]\n",
    "\n",
    "            # Count number of different node types\n",
    "            count_cn = len(filtered_nodes['cn'])\n",
    "            count_one_hop = len(filtered_nodes['one_hop'])\n",
    "            count_multi_hop = len(filtered_nodes['multi_hop'])\n",
    "            count_vector = torch.tensor([count_cn, count_one_hop, count_multi_hop], \n",
    "                                       device=self.device)\n",
    "\n",
    "            # Final prediction using Equation (11)\n",
    "            pred = self.predictor(torch.cat([\n",
    "                node_product, \n",
    "                pairwise_encoding.squeeze(0), \n",
    "                count_vector\n",
    "            ]))\n",
    "            predictions.append(pred)\n",
    "\n",
    "        #if total_links > 100:\n",
    "        #    print(f\"Processed all {total_links} links\")\n",
    "            \n",
    "        return torch.cat(predictions).squeeze(-1)  # Ensure output is [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ot_Ggzs4Vkb"
   },
   "source": [
    "## 5. Training and Evaluation Functions\n",
    "\n",
    "We implement the training and evaluation procedures with appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ck1Yk9Ys4Vkb"
   },
   "outputs": [],
   "source": [
    "class MRREvaluator:\n",
    "    \"\"\"Evaluator for Mean Reciprocal Rank (MRR) metric.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = 'mrr'\n",
    "\n",
    "    def eval(self, pred_dict):\n",
    "        \"\"\"Evaluate MRR.\"\"\"\n",
    "        y_pred_pos = pred_dict['y_pred_pos']\n",
    "        y_pred_neg = pred_dict['y_pred_neg']\n",
    "\n",
    "        # For each positive edge, compute its rank against negative edges\n",
    "        mrr_list = []\n",
    "        for i in range(y_pred_pos.shape[0]):\n",
    "            # Ensure y_pred_neg[i] is a tensor with at least one dimension\n",
    "            if y_pred_neg[i].dim() == 0:  # If it's a scalar tensor\n",
    "                neg_pred = y_pred_neg[i].unsqueeze(0)  # Make it [1]\n",
    "            else:\n",
    "                neg_pred = y_pred_neg[i]\n",
    "                \n",
    "            # Combine positive and negative predictions\n",
    "            y_pred = torch.cat([y_pred_pos[i:i+1], neg_pred])\n",
    "            # Sort in descending order\n",
    "            _, indices = torch.sort(y_pred, descending=True)\n",
    "            # Find rank of positive edge (should be at index 0)\n",
    "            rank = torch.where(indices == 0)[0].item() + 1\n",
    "            # Compute reciprocal rank\n",
    "            mrr_list.append(1.0 / rank)\n",
    "\n",
    "        return {'mrr': torch.tensor(mrr_list).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vy_1Zcxu4Vkb"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, data, split_edge, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: LPFormer model\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        data: PyG Data object\n",
    "        split_edge: Dictionary of train/val/test edge splits\n",
    "        batch_size: Batch size for training\n",
    "\n",
    "    Returns:\n",
    "        Average loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    device = model.device\n",
    "\n",
    "    # Get positive and negative edges\n",
    "    pos_train_edge = split_edge['train']['edge'].to(device)\n",
    "    neg_train_edge = split_edge['train']['edge_neg'].to(device)\n",
    "\n",
    "    # Create positive and negative labels\n",
    "    pos_train_label = torch.ones(pos_train_edge.size(0), dtype=torch.float, device=device)\n",
    "    neg_train_label = torch.zeros(neg_train_edge.size(0), dtype=torch.float, device=device)\n",
    "\n",
    "    # Combine positive and negative edges and labels\n",
    "    train_edge = torch.cat([pos_train_edge, neg_train_edge], dim=0)\n",
    "    train_label = torch.cat([pos_train_label, neg_train_label], dim=0)\n",
    "\n",
    "    # Shuffle the data\n",
    "    perm = torch.randperm(train_edge.size(0))\n",
    "    train_edge = train_edge[perm]\n",
    "    train_label = train_label[perm]\n",
    "\n",
    "    # Train in batches\n",
    "    total_loss = 0\n",
    "    num_batches = (train_edge.size(0) + batch_size - 1) // batch_size  # Ceiling division\n",
    "    \n",
    "    print(f\"Training on {train_edge.size(0)} edges in {num_batches} batches...\")\n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "    update_interval = 30  # seconds\n",
    "    \n",
    "    for batch_idx, idx in enumerate(range(0, train_edge.size(0), batch_size)):\n",
    "        # Show progress update periodically\n",
    "        current_time = time.time()\n",
    "        if current_time - last_update_time > update_interval:\n",
    "            progress = (batch_idx + 1) / num_batches\n",
    "            elapsed = current_time - start_time\n",
    "            eta = elapsed / progress - elapsed if progress > 0 else 0\n",
    "            print(f\"Batch {batch_idx+1}/{num_batches} ({progress*100:.1f}%), \"\n",
    "                  f\"Elapsed: {elapsed:.1f}s, ETA: {eta:.1f}s\")\n",
    "            last_update_time = current_time\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_edge = train_edge[idx:idx+batch_size]\n",
    "        batch_label = train_label[idx:idx+batch_size]\n",
    "\n",
    "        pred = model(data.x, data.edge_index, batch_edge)\n",
    "        loss = F.binary_cross_entropy(pred, batch_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch_edge.size(0)\n",
    "\n",
    "    # Update learning rate\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return total_loss / train_edge.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2ygKJYDl4Vkc"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, split_edge, evaluator, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation or test set.\n",
    "\n",
    "    Args:\n",
    "        model: LPFormer model\n",
    "        data: PyG Data object\n",
    "        split_edge: Dictionary of train/val/test edge splits\n",
    "        evaluator: Evaluator object for computing metrics\n",
    "        batch_size: Batch size for evaluation\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    print(\"Evaluating on validation set...\")\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(device)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm]\n",
    "        pos_valid_preds.append(model(data.x, data.edge_index, edge).cpu())\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm]\n",
    "        neg_valid_preds.append(model(data.x, data.edge_index, edge).cpu())\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    pos_test_edge = split_edge['test']['edge'].to(device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(device)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm]\n",
    "        pos_test_preds.append(model(data.x, data.edge_index, edge).cpu())\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm]\n",
    "        neg_test_preds.append(model(data.x, data.edge_index, edge).cpu())\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    print(\"Computing evaluation metrics...\")\n",
    "    results = {}\n",
    "\n",
    "    # Prepare data for MRR evaluation\n",
    "    # For validation set\n",
    "    valid_mrr_data = {\n",
    "        'y_pred_pos': pos_valid_pred,\n",
    "        'y_pred_neg': []\n",
    "    }\n",
    "    \n",
    "    # Ensure each positive edge has corresponding negative edges\n",
    "    neg_per_pos = neg_valid_edge.size(0) // pos_valid_edge.size(0)\n",
    "    for i in range(pos_valid_edge.size(0)):\n",
    "        start_idx = i * neg_per_pos\n",
    "        end_idx = start_idx + neg_per_pos\n",
    "        # Handle the case where division isn't perfect\n",
    "        if i == pos_valid_edge.size(0) - 1:\n",
    "            end_idx = neg_valid_edge.size(0)\n",
    "        valid_mrr_data['y_pred_neg'].append(neg_valid_pred[start_idx:end_idx])\n",
    "    \n",
    "    # For test set\n",
    "    test_mrr_data = {\n",
    "        'y_pred_pos': pos_test_pred,\n",
    "        'y_pred_neg': []\n",
    "    }\n",
    "    \n",
    "    neg_per_pos = neg_test_edge.size(0) // pos_test_edge.size(0)\n",
    "    for i in range(pos_test_edge.size(0)):\n",
    "        start_idx = i * neg_per_pos\n",
    "        end_idx = start_idx + neg_per_pos\n",
    "        # Handle the case where division isn't perfect\n",
    "        if i == pos_test_edge.size(0) - 1:\n",
    "            end_idx = neg_test_edge.size(0)\n",
    "        test_mrr_data['y_pred_neg'].append(neg_test_pred[start_idx:end_idx])\n",
    "    \n",
    "    # Compute MRR\n",
    "    results['valid'] = evaluator.eval(valid_mrr_data)['mrr']\n",
    "    results['test'] = evaluator.eval(test_mrr_data)['mrr']\n",
    "\n",
    "    # Also compute AUC and AP for additional evaluation\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "    # Validation AUC and AP\n",
    "    valid_pred = torch.cat([pos_valid_pred, neg_valid_pred])\n",
    "    valid_true = torch.cat([torch.ones(pos_valid_pred.size(0)), torch.zeros(neg_valid_pred.size(0))])\n",
    "    valid_auc = roc_auc_score(valid_true, valid_pred)\n",
    "    valid_ap = average_precision_score(valid_true, valid_pred)\n",
    "\n",
    "    # Test AUC and AP\n",
    "    test_pred = torch.cat([pos_test_pred, neg_test_pred])\n",
    "    test_true = torch.cat([torch.ones(pos_test_pred.size(0)), torch.zeros(neg_test_pred.size(0))])\n",
    "    test_auc = roc_auc_score(test_true, test_pred)\n",
    "    test_ap = average_precision_score(test_true, test_pred)\n",
    "\n",
    "    results['valid_auc'] = valid_auc\n",
    "    results['valid_ap'] = valid_ap\n",
    "    results['test_auc'] = test_auc\n",
    "    results['test_ap'] = test_ap\n",
    "\n",
    "    evaluation_time = time.time() - start_time\n",
    "    print(f\"Evaluation completed in {evaluation_time:.2f} seconds\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9jtJKO4Vkc"
   },
   "source": [
    "## 6. LP Factor Analysis\n",
    "\n",
    "We implement the LP factor analysis as described in the paper to evaluate performance on different types of links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Oc-Zt9Gu4Vkc"
   },
   "outputs": [],
   "source": [
    "def analyze_lp_factors(model, data, split_edge, percentile=90):\n",
    "    \"\"\"\n",
    "    Analyze model performance by LP factor type (local, global, feature proximity).\n",
    "\n",
    "    Args:\n",
    "        model: LPFormer model\n",
    "        data: PyG Data object\n",
    "        split_edge: Dictionary of train/val/test edge splits\n",
    "        percentile: Percentile threshold for factor dominance\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of performance metrics by factor type\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    # Get test edges\n",
    "    pos_test_edge = split_edge['test']['edge'].to(device)\n",
    "\n",
    "    # Compute heuristic scores for each factor\n",
    "    print(\"Computing heuristic scores for LP factors...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Local structural information: Common Neighbors (CN)\n",
    "    print(\"Computing Common Neighbors (CN) scores...\")\n",
    "    cn_scores = []\n",
    "    for edge in tqdm(pos_test_edge, desc=\"Computing CN scores\"):\n",
    "        a, b = edge\n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "        neighbors_a = set((data.edge_index[0] == a).nonzero().flatten().cpu().numpy())\n",
    "        neighbors_b = set((data.edge_index[0] == b).nonzero().flatten().cpu().numpy())\n",
    "        cn_score = len(neighbors_a.intersection(neighbors_b))\n",
    "        cn_scores.append(cn_score)\n",
    "    cn_scores = torch.tensor(cn_scores, device=device)\n",
    "\n",
    "    # Global structural information: PPR\n",
    "    print(\"Computing PPR scores...\")\n",
    "    ppr_scores = []\n",
    "    for edge in tqdm(pos_test_edge, desc=\"Computing PPR scores\"):\n",
    "        a, b = edge\n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "        ppr_score = model.ppr_matrix[a, b].item()\n",
    "        ppr_scores.append(ppr_score)\n",
    "    ppr_scores = torch.tensor(ppr_scores, device=device)\n",
    "\n",
    "    # Feature proximity: Cosine similarity\n",
    "    print(\"Computing feature similarity scores...\")\n",
    "    feat_scores = []\n",
    "    for edge in tqdm(pos_test_edge, desc=\"Computing feature similarity scores\"):\n",
    "        a, b = edge\n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "        feat_a = data.x[a]\n",
    "        feat_b = data.x[b]\n",
    "        feat_sim = F.cosine_similarity(feat_a.unsqueeze(0), feat_b.unsqueeze(0)).item()\n",
    "        feat_scores.append(feat_sim)\n",
    "    feat_scores = torch.tensor(feat_scores, device=device)\n",
    "\n",
    "    # Compute percentile thresholds\n",
    "    cn_threshold = torch.quantile(cn_scores.float(), percentile/100)\n",
    "    ppr_threshold = torch.quantile(ppr_scores.float(), percentile/100)\n",
    "    feat_threshold = torch.quantile(feat_scores.float(), percentile/100)\n",
    "\n",
    "    print(f\"Percentile thresholds (p={percentile}):\\n  CN: {cn_threshold:.4f}\\n  PPR: {ppr_threshold:.4f}\\n  Feature: {feat_threshold:.4f}\")\n",
    "\n",
    "    # Categorize edges by dominant factor\n",
    "    print(\"Categorizing edges by dominant factor...\")\n",
    "    local_edges = []\n",
    "    global_edges = []\n",
    "    feature_edges = []\n",
    "\n",
    "    for i, edge in enumerate(pos_test_edge):\n",
    "        # Check if only one factor is dominant\n",
    "        is_local_dominant = cn_scores[i] >= cn_threshold\n",
    "        is_global_dominant = ppr_scores[i] >= ppr_threshold\n",
    "        is_feature_dominant = feat_scores[i] >= feat_threshold\n",
    "\n",
    "        dominant_count = sum([is_local_dominant, is_global_dominant, is_feature_dominant])\n",
    "\n",
    "        if dominant_count == 1:\n",
    "            if is_local_dominant:\n",
    "                local_edges.append(i)\n",
    "            elif is_global_dominant:\n",
    "                global_edges.append(i)\n",
    "            elif is_feature_dominant:\n",
    "                feature_edges.append(i)\n",
    "\n",
    "    local_edges = torch.tensor(local_edges, device=device)\n",
    "    global_edges = torch.tensor(global_edges, device=device)\n",
    "    feature_edges = torch.tensor(feature_edges, device=device)\n",
    "\n",
    "    print(f\"Edges categorized by dominant factor:\\n  Local: {len(local_edges)}\\n  Global: {len(global_edges)}\\n  Feature: {len(feature_edges)}\")\n",
    "\n",
    "    # Evaluate model performance on each category\n",
    "    print(\"Evaluating model performance by factor type...\")\n",
    "    results = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Evaluate on local factor edges\n",
    "        if len(local_edges) > 0:\n",
    "            print(\"Evaluating on local factor edges...\")\n",
    "            local_pred = model(data.x, data.edge_index, pos_test_edge[local_edges])\n",
    "            results['local'] = local_pred.mean().item()\n",
    "        else:\n",
    "            results['local'] = float('nan')\n",
    "\n",
    "        # Evaluate on global factor edges\n",
    "        if len(global_edges) > 0:\n",
    "            print(\"Evaluating on global factor edges...\")\n",
    "            global_pred = model(data.x, data.edge_index, pos_test_edge[global_edges])\n",
    "            results['global'] = global_pred.mean().item()\n",
    "        else:\n",
    "            results['global'] = float('nan')\n",
    "\n",
    "        # Evaluate on feature factor edges\n",
    "        if len(feature_edges) > 0:\n",
    "            print(\"Evaluating on feature factor edges...\")\n",
    "            feature_pred = model(data.x, data.edge_index, pos_test_edge[feature_edges])\n",
    "            results['feature'] = feature_pred.mean().item()\n",
    "        else:\n",
    "            results['feature'] = float('nan')\n",
    "\n",
    "    analysis_time = time.time() - start_time\n",
    "    print(f\"LP factor analysis completed in {analysis_time:.2f} seconds\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvxQvXI4Vkc"
   },
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "We train and evaluate the LPFormer model on the Marvel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ow-Yx5G4Vkc",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using hyperparameters:\n",
      "  hidden_dim: 128\n",
      "  learning_rate: 0.001\n",
      "  decay: 0.95\n",
      "  dropout: 0.3\n",
      "  weight_decay: 0.0001\n",
      "  ppr_threshold: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Create evaluator\n",
    "evaluator = MRREvaluator()\n",
    "\n",
    "# Set hyperparameters\n",
    "hyperparams = {\n",
    "    'hidden_dim': 128,\n",
    "    'learning_rate': 1e-3,\n",
    "    'decay': 0.95,\n",
    "    'dropout': 0.3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'ppr_threshold': 1e-3\n",
    "}\n",
    "\n",
    "print(f\"\\nUsing hyperparameters:\")\n",
    "for key, value in hyperparams.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Move data to device\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ow-Yx5G4Vkc",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LPFormer model...\n",
      "\n",
      "----- Initializing LPFormer Model -----\n",
      "Number of nodes: 19090\n",
      "Hidden dimension: 128\n",
      "Number of layers: 2\n",
      "Number of attention heads: 4\n",
      "Using device: cuda\n",
      "Node feature dimension: 3\n",
      "Creating GCN layers for node representation...\n",
      "  Added GCN layer 1 with hidden_dim 128\n",
      "Computing PPR matrix using Andersen's algorithm...\n",
      "Computing PPR matrix for 19090 nodes using Andersen's algorithm...\n",
      "This may take a while for large graphs. Please be patient.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00f4a14436c480da04de32027d0c92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing PPR:   0%|          | 0/19090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.4% (80/19090), Elapsed: 5.0s, ETA: 1193.5s\n",
      "Progress: 0.8% (156/19090), Elapsed: 10.1s, ETA: 1220.6s\n",
      "Progress: 1.4% (259/19090), Elapsed: 15.1s, ETA: 1098.2s\n",
      "Progress: 1.9% (359/19090), Elapsed: 20.1s, ETA: 1051.1s\n",
      "Progress: 2.3% (445/19090), Elapsed: 25.2s, ETA: 1054.0s\n",
      "Progress: 2.9% (545/19090), Elapsed: 30.2s, ETA: 1026.9s\n",
      "Progress: 3.9% (735/19090), Elapsed: 35.2s, ETA: 879.1s\n",
      "Progress: 4.4% (835/19090), Elapsed: 40.2s, ETA: 879.2s\n",
      "Progress: 4.9% (927/19090), Elapsed: 45.2s, ETA: 886.1s\n",
      "Progress: 5.4% (1038/19090), Elapsed: 50.3s, ETA: 874.1s\n",
      "Progress: 6.0% (1137/19090), Elapsed: 55.3s, ETA: 872.7s\n",
      "Progress: 6.5% (1241/19090), Elapsed: 60.4s, ETA: 868.2s\n",
      "Progress: 7.0% (1343/19090), Elapsed: 65.4s, ETA: 863.9s\n",
      "Progress: 7.6% (1445/19090), Elapsed: 70.4s, ETA: 859.5s\n",
      "Progress: 8.1% (1555/19090), Elapsed: 75.4s, ETA: 850.7s\n",
      "Progress: 8.8% (1677/19090), Elapsed: 80.5s, ETA: 835.9s\n",
      "Progress: 9.4% (1789/19090), Elapsed: 85.6s, ETA: 827.6s\n",
      "Progress: 10.0% (1900/19090), Elapsed: 90.6s, ETA: 819.8s\n",
      "Progress: 10.5% (2012/19090), Elapsed: 95.7s, ETA: 812.1s\n",
      "Progress: 11.0% (2106/19090), Elapsed: 100.7s, ETA: 812.2s\n",
      "Progress: 11.6% (2222/19090), Elapsed: 105.7s, ETA: 802.7s\n",
      "Progress: 12.4% (2360/19090), Elapsed: 110.8s, ETA: 785.4s\n",
      "Progress: 13.2% (2519/19090), Elapsed: 115.8s, ETA: 761.8s\n",
      "Progress: 13.9% (2652/19090), Elapsed: 120.8s, ETA: 749.0s\n",
      "Progress: 14.5% (2759/19090), Elapsed: 125.9s, ETA: 745.2s\n",
      "Progress: 15.1% (2890/19090), Elapsed: 130.9s, ETA: 733.8s\n",
      "Progress: 15.7% (2999/19090), Elapsed: 135.9s, ETA: 729.4s\n",
      "Progress: 16.2% (3099/19090), Elapsed: 141.0s, ETA: 727.6s\n",
      "Progress: 16.7% (3189/19090), Elapsed: 146.0s, ETA: 728.2s\n",
      "Progress: 17.4% (3325/19090), Elapsed: 151.1s, ETA: 716.3s\n",
      "Progress: 18.0% (3433/19090), Elapsed: 156.1s, ETA: 712.0s\n",
      "Progress: 18.6% (3559/19090), Elapsed: 161.2s, ETA: 703.3s\n",
      "Progress: 19.2% (3666/19090), Elapsed: 166.2s, ETA: 699.2s\n",
      "Progress: 20.0% (3810/19090), Elapsed: 171.2s, ETA: 686.7s\n",
      "Progress: 20.5% (3915/19090), Elapsed: 176.2s, ETA: 683.1s\n",
      "Progress: 21.2% (4041/19090), Elapsed: 181.2s, ETA: 675.0s\n",
      "Progress: 21.9% (4184/19090), Elapsed: 186.3s, ETA: 663.6s\n",
      "Progress: 22.7% (4335/19090), Elapsed: 191.3s, ETA: 651.0s\n",
      "Progress: 23.4% (4467/19090), Elapsed: 196.3s, ETA: 642.5s\n",
      "Progress: 24.2% (4618/19090), Elapsed: 201.3s, ETA: 630.8s\n",
      "Progress: 24.9% (4760/19090), Elapsed: 206.3s, ETA: 621.0s\n",
      "Progress: 25.5% (4867/19090), Elapsed: 211.3s, ETA: 617.5s\n",
      "Progress: 26.2% (4993/19090), Elapsed: 216.3s, ETA: 610.8s\n",
      "Progress: 26.9% (5136/19090), Elapsed: 221.4s, ETA: 601.4s\n",
      "Progress: 27.7% (5294/19090), Elapsed: 226.4s, ETA: 590.0s\n",
      "Progress: 28.3% (5398/19090), Elapsed: 231.5s, ETA: 587.1s\n",
      "Progress: 28.8% (5501/19090), Elapsed: 236.5s, ETA: 584.2s\n",
      "Progress: 29.3% (5599/19090), Elapsed: 241.5s, ETA: 581.9s\n",
      "Progress: 29.8% (5693/19090), Elapsed: 246.6s, ETA: 580.2s\n",
      "Progress: 30.4% (5799/19090), Elapsed: 251.6s, ETA: 576.6s\n",
      "Progress: 30.8% (5882/19090), Elapsed: 256.6s, ETA: 576.2s\n",
      "Progress: 31.3% (5980/19090), Elapsed: 261.6s, ETA: 573.6s\n",
      "Progress: 31.8% (6073/19090), Elapsed: 266.7s, ETA: 571.6s\n",
      "Progress: 32.4% (6183/19090), Elapsed: 271.7s, ETA: 567.2s\n",
      "Progress: 32.9% (6287/19090), Elapsed: 276.8s, ETA: 563.6s\n",
      "Progress: 33.5% (6394/19090), Elapsed: 281.8s, ETA: 559.6s\n",
      "Progress: 34.3% (6551/19090), Elapsed: 286.8s, ETA: 549.0s\n",
      "Progress: 35.0% (6689/19090), Elapsed: 291.9s, ETA: 541.1s\n",
      "Progress: 35.6% (6791/19090), Elapsed: 296.9s, ETA: 537.8s\n",
      "Progress: 36.3% (6936/19090), Elapsed: 302.0s, ETA: 529.1s\n",
      "Progress: 37.1% (7077/19090), Elapsed: 307.0s, ETA: 521.1s\n",
      "Progress: 37.7% (7204/19090), Elapsed: 312.0s, ETA: 514.8s\n",
      "Progress: 38.4% (7325/19090), Elapsed: 317.0s, ETA: 509.2s\n",
      "Progress: 39.1% (7472/19090), Elapsed: 322.0s, ETA: 500.7s\n",
      "Progress: 39.8% (7590/19090), Elapsed: 327.0s, ETA: 495.5s\n",
      "Progress: 40.4% (7710/19090), Elapsed: 332.0s, ETA: 490.1s\n",
      "Progress: 40.9% (7814/19090), Elapsed: 337.1s, ETA: 486.4s\n",
      "Progress: 41.5% (7920/19090), Elapsed: 342.1s, ETA: 482.4s\n",
      "Progress: 42.1% (8032/19090), Elapsed: 347.1s, ETA: 477.8s\n",
      "Progress: 42.6% (8127/19090), Elapsed: 352.1s, ETA: 475.0s\n",
      "Progress: 43.1% (8223/19090), Elapsed: 357.1s, ETA: 472.0s\n",
      "Progress: 43.6% (8332/19090), Elapsed: 362.2s, ETA: 467.6s\n",
      "Progress: 44.1% (8418/19090), Elapsed: 367.2s, ETA: 465.5s\n",
      "Progress: 44.9% (8564/19090), Elapsed: 372.2s, ETA: 457.5s\n",
      "Progress: 45.5% (8678/19090), Elapsed: 377.2s, ETA: 452.6s\n",
      "Progress: 46.1% (8796/19090), Elapsed: 382.2s, ETA: 447.3s\n",
      "Progress: 46.6% (8900/19090), Elapsed: 387.3s, ETA: 443.4s\n",
      "Progress: 47.4% (9040/19090), Elapsed: 392.3s, ETA: 436.1s\n",
      "Progress: 47.9% (9144/19090), Elapsed: 397.3s, ETA: 432.2s\n",
      "Progress: 48.5% (9256/19090), Elapsed: 402.3s, ETA: 427.5s\n",
      "Progress: 49.0% (9361/19090), Elapsed: 407.4s, ETA: 423.4s\n",
      "Progress: 49.9% (9518/19090), Elapsed: 412.4s, ETA: 414.7s\n",
      "Progress: 50.6% (9660/19090), Elapsed: 417.4s, ETA: 407.5s\n",
      "Progress: 51.5% (9827/19090), Elapsed: 422.4s, ETA: 398.2s\n",
      "Progress: 52.2% (9974/19090), Elapsed: 427.5s, ETA: 390.7s\n",
      "Progress: 53.0% (10114/19090), Elapsed: 432.5s, ETA: 383.8s\n",
      "Progress: 53.5% (10218/19090), Elapsed: 437.5s, ETA: 379.8s\n",
      "Progress: 54.1% (10322/19090), Elapsed: 442.5s, ETA: 375.9s\n",
      "Progress: 54.6% (10414/19090), Elapsed: 447.5s, ETA: 372.8s\n",
      "Progress: 55.1% (10515/19090), Elapsed: 452.5s, ETA: 369.1s\n",
      "Progress: 55.6% (10614/19090), Elapsed: 457.6s, ETA: 365.4s\n",
      "Progress: 56.1% (10711/19090), Elapsed: 462.6s, ETA: 361.9s\n",
      "Progress: 56.7% (10815/19090), Elapsed: 467.6s, ETA: 357.8s\n",
      "Progress: 57.2% (10922/19090), Elapsed: 472.6s, ETA: 353.4s\n",
      "Progress: 58.0% (11070/19090), Elapsed: 477.7s, ETA: 346.1s\n",
      "Progress: 58.8% (11216/19090), Elapsed: 482.7s, ETA: 338.9s\n",
      "Progress: 59.2% (11308/19090), Elapsed: 487.7s, ETA: 335.7s\n",
      "Progress: 59.9% (11435/19090), Elapsed: 492.8s, ETA: 329.9s\n",
      "Progress: 60.5% (11548/19090), Elapsed: 497.8s, ETA: 325.1s\n",
      "Progress: 61.2% (11680/19090), Elapsed: 502.9s, ETA: 319.0s\n",
      "Progress: 62.1% (11861/19090), Elapsed: 508.0s, ETA: 309.6s\n",
      "Progress: 62.9% (12010/19090), Elapsed: 513.0s, ETA: 302.4s\n",
      "Progress: 63.4% (12102/19090), Elapsed: 518.1s, ETA: 299.1s\n",
      "Progress: 63.9% (12201/19090), Elapsed: 523.1s, ETA: 295.3s\n",
      "Progress: 64.4% (12297/19090), Elapsed: 528.1s, ETA: 291.7s\n",
      "Progress: 65.3% (12457/19090), Elapsed: 533.1s, ETA: 283.9s\n",
      "Progress: 66.0% (12596/19090), Elapsed: 538.2s, ETA: 277.5s\n",
      "Progress: 66.5% (12698/19090), Elapsed: 543.3s, ETA: 273.5s\n",
      "Progress: 67.0% (12785/19090), Elapsed: 548.3s, ETA: 270.4s\n",
      "Progress: 67.5% (12887/19090), Elapsed: 553.3s, ETA: 266.3s\n",
      "Progress: 68.2% (13020/19090), Elapsed: 558.3s, ETA: 260.3s\n",
      "Progress: 69.1% (13197/19090), Elapsed: 563.4s, ETA: 251.6s\n",
      "Progress: 69.6% (13288/19090), Elapsed: 568.4s, ETA: 248.2s\n",
      "Progress: 70.1% (13383/19090), Elapsed: 573.4s, ETA: 244.5s\n",
      "Progress: 70.6% (13485/19090), Elapsed: 578.4s, ETA: 240.4s\n",
      "Progress: 71.4% (13638/19090), Elapsed: 583.5s, ETA: 233.3s\n",
      "Progress: 72.1% (13770/19090), Elapsed: 588.5s, ETA: 227.4s\n",
      "Progress: 72.7% (13870/19090), Elapsed: 593.5s, ETA: 223.4s\n",
      "Progress: 73.3% (13994/19090), Elapsed: 598.5s, ETA: 218.0s\n",
      "Progress: 73.9% (14107/19090), Elapsed: 603.6s, ETA: 213.2s\n",
      "Progress: 74.4% (14200/19090), Elapsed: 608.6s, ETA: 209.6s\n",
      "Progress: 74.9% (14303/19090), Elapsed: 613.6s, ETA: 205.4s\n",
      "Progress: 75.6% (14426/19090), Elapsed: 618.7s, ETA: 200.0s\n",
      "Progress: 76.2% (14546/19090), Elapsed: 623.7s, ETA: 194.8s\n",
      "Progress: 76.8% (14666/19090), Elapsed: 628.8s, ETA: 189.7s\n",
      "Progress: 77.5% (14803/19090), Elapsed: 633.8s, ETA: 183.6s\n",
      "Progress: 78.4% (14959/19090), Elapsed: 638.8s, ETA: 176.4s\n",
      "Progress: 79.0% (15081/19090), Elapsed: 643.9s, ETA: 171.2s\n",
      "Progress: 79.7% (15208/19090), Elapsed: 648.9s, ETA: 165.6s\n",
      "Progress: 80.2% (15302/19090), Elapsed: 653.9s, ETA: 161.9s\n",
      "Progress: 80.8% (15425/19090), Elapsed: 658.9s, ETA: 156.6s\n",
      "Progress: 81.2% (15510/19090), Elapsed: 664.0s, ETA: 153.3s\n",
      "Progress: 81.9% (15642/19090), Elapsed: 669.0s, ETA: 147.5s\n",
      "Progress: 82.8% (15804/19090), Elapsed: 674.0s, ETA: 140.1s\n",
      "Progress: 83.6% (15964/19090), Elapsed: 679.0s, ETA: 133.0s\n",
      "Progress: 84.3% (16088/19090), Elapsed: 684.1s, ETA: 127.7s\n",
      "Progress: 84.9% (16203/19090), Elapsed: 689.1s, ETA: 122.8s\n",
      "Progress: 85.4% (16308/19090), Elapsed: 694.2s, ETA: 118.4s\n",
      "Progress: 86.1% (16437/19090), Elapsed: 699.2s, ETA: 112.9s\n",
      "Progress: 86.7% (16550/19090), Elapsed: 704.2s, ETA: 108.1s\n",
      "Progress: 87.3% (16670/19090), Elapsed: 709.2s, ETA: 103.0s\n",
      "Progress: 88.1% (16823/19090), Elapsed: 714.3s, ETA: 96.3s\n",
      "Progress: 88.7% (16927/19090), Elapsed: 719.4s, ETA: 91.9s\n",
      "Progress: 89.2% (17028/19090), Elapsed: 724.4s, ETA: 87.7s\n",
      "Progress: 89.9% (17160/19090), Elapsed: 729.4s, ETA: 82.0s\n",
      "Progress: 90.5% (17274/19090), Elapsed: 734.4s, ETA: 77.2s\n",
      "Progress: 91.0% (17379/19090), Elapsed: 739.5s, ETA: 72.8s\n",
      "Progress: 91.6% (17491/19090), Elapsed: 744.5s, ETA: 68.1s\n",
      "Progress: 92.3% (17616/19090), Elapsed: 749.6s, ETA: 62.7s\n",
      "Progress: 93.0% (17745/19090), Elapsed: 754.6s, ETA: 57.2s\n",
      "Progress: 93.6% (17870/19090), Elapsed: 759.6s, ETA: 51.9s\n",
      "Progress: 94.2% (17975/19090), Elapsed: 764.7s, ETA: 47.4s\n",
      "Progress: 94.7% (18087/19090), Elapsed: 769.7s, ETA: 42.7s\n",
      "Progress: 95.2% (18177/19090), Elapsed: 774.7s, ETA: 38.9s\n",
      "Progress: 95.8% (18285/19090), Elapsed: 779.7s, ETA: 34.3s\n",
      "Progress: 96.4% (18398/19090), Elapsed: 784.8s, ETA: 29.5s\n",
      "Progress: 97.1% (18533/19090), Elapsed: 789.8s, ETA: 23.7s\n",
      "Progress: 98.0% (18700/19090), Elapsed: 794.8s, ETA: 16.6s\n",
      "Progress: 98.8% (18865/19090), Elapsed: 799.8s, ETA: 9.5s\n",
      "Progress: 99.6% (19005/19090), Elapsed: 804.9s, ETA: 3.6s\n",
      "PPR matrix computation completed in 808.86 seconds!\n",
      "PPR matrix shape: torch.Size([19090, 19090]), device: cuda:0\n",
      "Creating adjacency matrix...\n",
      "Adjacency matrix shape: torch.Size([19090, 19090]), device: cuda:0\n",
      "Creating PPR thresholding module...\n",
      "Creating PPR positional encoding module with order invariance...\n",
      "Creating GATv2 attention layers...\n",
      "  Added GATv2 attention layer 1\n",
      "  Added GATv2 attention layer 2\n",
      "Creating final prediction layer...\n",
      "LPFormer model initialized successfully!\n",
      "-----------------------------------------\n",
      "\n",
      "Initializing optimizer and scheduler...\n",
      "Model initialization completed in 809.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing LPFormer model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = LPFormer(\n",
    "    num_nodes=data.num_nodes,\n",
    "    node_features=data.x,\n",
    "    edge_index=data.edge_index,\n",
    "    hidden_dim=hyperparams['hidden_dim'],\n",
    "    num_layers=2,\n",
    "    num_heads=4,\n",
    "    dropout=hyperparams['dropout'],\n",
    "    ppr_threshold=hyperparams['ppr_threshold']\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "print(\"Initializing optimizer and scheduler...\")\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hyperparams['learning_rate'],\n",
    "    weight_decay=hyperparams['weight_decay']\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=hyperparams['decay']\n",
    ")\n",
    "\n",
    "initialization_time = time.time() - start_time\n",
    "print(f\"Model initialization completed in {initialization_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ow-Yx5G4Vkc",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training LPFormer on Marvel dataset for 1 epochs...\n",
      "==================================================\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch 1/1\n",
      "--------------------------------------------------\n",
      "Training on 153326 edges in 150 batches...\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 3/150 (2.0%), Elapsed: 42.1s, ETA: 2061.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 5/150 (3.3%), Elapsed: 80.9s, ETA: 2345.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 7/150 (4.7%), Elapsed: 121.0s, ETA: 2472.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 9/150 (6.0%), Elapsed: 161.0s, ETA: 2522.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 11/150 (7.3%), Elapsed: 201.1s, ETA: 2541.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 13/150 (8.7%), Elapsed: 241.4s, ETA: 2543.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 15/150 (10.0%), Elapsed: 281.7s, ETA: 2535.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 17/150 (11.3%), Elapsed: 322.0s, ETA: 2519.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 19/150 (12.7%), Elapsed: 361.5s, ETA: 2492.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 21/150 (14.0%), Elapsed: 402.3s, ETA: 2471.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 23/150 (15.3%), Elapsed: 443.5s, ETA: 2448.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 25/150 (16.7%), Elapsed: 484.7s, ETA: 2423.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 27/150 (18.0%), Elapsed: 525.2s, ETA: 2392.4s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 29/150 (19.3%), Elapsed: 565.5s, ETA: 2359.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 31/150 (20.7%), Elapsed: 606.4s, ETA: 2327.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 33/150 (22.0%), Elapsed: 647.0s, ETA: 2293.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 35/150 (23.3%), Elapsed: 687.8s, ETA: 2260.1s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 37/150 (24.7%), Elapsed: 728.0s, ETA: 2223.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 39/150 (26.0%), Elapsed: 768.0s, ETA: 2185.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 41/150 (27.3%), Elapsed: 807.8s, ETA: 2147.4s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 43/150 (28.7%), Elapsed: 848.3s, ETA: 2110.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 45/150 (30.0%), Elapsed: 888.7s, ETA: 2073.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 47/150 (31.3%), Elapsed: 928.4s, ETA: 2034.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 49/150 (32.7%), Elapsed: 968.0s, ETA: 1995.3s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 51/150 (34.0%), Elapsed: 1007.5s, ETA: 1955.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 53/150 (35.3%), Elapsed: 1047.0s, ETA: 1916.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 55/150 (36.7%), Elapsed: 1087.4s, ETA: 1878.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 57/150 (38.0%), Elapsed: 1126.8s, ETA: 1838.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 59/150 (39.3%), Elapsed: 1166.5s, ETA: 1799.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 61/150 (40.7%), Elapsed: 1206.1s, ETA: 1759.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 63/150 (42.0%), Elapsed: 1246.1s, ETA: 1720.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 65/150 (43.3%), Elapsed: 1285.6s, ETA: 1681.1s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 67/150 (44.7%), Elapsed: 1324.8s, ETA: 1641.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 69/150 (46.0%), Elapsed: 1364.3s, ETA: 1601.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 71/150 (47.3%), Elapsed: 1404.1s, ETA: 1562.3s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 73/150 (48.7%), Elapsed: 1443.4s, ETA: 1522.4s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 75/150 (50.0%), Elapsed: 1482.5s, ETA: 1482.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 77/150 (51.3%), Elapsed: 1521.6s, ETA: 1442.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 79/150 (52.7%), Elapsed: 1560.6s, ETA: 1402.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 81/150 (54.0%), Elapsed: 1600.0s, ETA: 1362.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 83/150 (55.3%), Elapsed: 1638.5s, ETA: 1322.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 85/150 (56.7%), Elapsed: 1676.8s, ETA: 1282.3s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 87/150 (58.0%), Elapsed: 1715.9s, ETA: 1242.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 89/150 (59.3%), Elapsed: 1755.2s, ETA: 1203.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 91/150 (60.7%), Elapsed: 1793.8s, ETA: 1163.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 93/150 (62.0%), Elapsed: 1832.6s, ETA: 1123.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 95/150 (63.3%), Elapsed: 1871.8s, ETA: 1083.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 97/150 (64.7%), Elapsed: 1910.4s, ETA: 1043.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 99/150 (66.0%), Elapsed: 1949.0s, ETA: 1004.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 101/150 (67.3%), Elapsed: 1987.6s, ETA: 964.3s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 103/150 (68.7%), Elapsed: 2026.0s, ETA: 924.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 105/150 (70.0%), Elapsed: 2065.0s, ETA: 885.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 107/150 (71.3%), Elapsed: 2103.6s, ETA: 845.4s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 109/150 (72.7%), Elapsed: 2141.6s, ETA: 805.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 111/150 (74.0%), Elapsed: 2180.2s, ETA: 766.0s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 113/150 (75.3%), Elapsed: 2218.8s, ETA: 726.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 115/150 (76.7%), Elapsed: 2257.5s, ETA: 687.1s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 117/150 (78.0%), Elapsed: 2295.8s, ETA: 647.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 119/150 (79.3%), Elapsed: 2334.8s, ETA: 608.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 121/150 (80.7%), Elapsed: 2373.4s, ETA: 568.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 123/150 (82.0%), Elapsed: 2412.0s, ETA: 529.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 125/150 (83.3%), Elapsed: 2450.8s, ETA: 490.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 127/150 (84.7%), Elapsed: 2489.3s, ETA: 450.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 129/150 (86.0%), Elapsed: 2528.1s, ETA: 411.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 131/150 (87.3%), Elapsed: 2566.3s, ETA: 372.2s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 133/150 (88.7%), Elapsed: 2604.8s, ETA: 332.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 135/150 (90.0%), Elapsed: 2643.4s, ETA: 293.7s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 137/150 (91.3%), Elapsed: 2681.7s, ETA: 254.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 139/150 (92.7%), Elapsed: 2720.1s, ETA: 215.3s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 141/150 (94.0%), Elapsed: 2758.6s, ETA: 176.1s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 143/150 (95.3%), Elapsed: 2797.1s, ETA: 136.9s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 145/150 (96.7%), Elapsed: 2834.9s, ETA: 97.8s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 147/150 (98.0%), Elapsed: 2873.2s, ETA: 58.6s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Batch 149/150 (99.3%), Elapsed: 2912.4s, ETA: 19.5s\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/750 (0.0%)\n",
      "Processing links: 75/750 (10.0%)\n",
      "Processing links: 150/750 (20.0%)\n",
      "Processing links: 225/750 (30.0%)\n",
      "Processing links: 300/750 (40.0%)\n",
      "Processing links: 375/750 (50.0%)\n",
      "Processing links: 450/750 (60.0%)\n",
      "Processing links: 525/750 (70.0%)\n",
      "Processing links: 600/750 (80.0%)\n",
      "Processing links: 675/750 (90.0%)\n",
      "Processed all 750 links\n",
      "Training completed in 2946.60 seconds\n",
      "Evaluating model...\n",
      "Evaluating on validation set...\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/366 (0.0%)\n",
      "Processing links: 36/366 (9.8%)\n",
      "Processing links: 72/366 (19.7%)\n",
      "Processing links: 108/366 (29.5%)\n",
      "Processing links: 144/366 (39.3%)\n",
      "Processing links: 180/366 (49.2%)\n",
      "Processing links: 216/366 (59.0%)\n",
      "Processing links: 252/366 (68.9%)\n",
      "Processing links: 288/366 (78.7%)\n",
      "Processing links: 324/366 (88.5%)\n",
      "Processing links: 360/366 (98.4%)\n",
      "Processed all 366 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/366 (0.0%)\n",
      "Processing links: 36/366 (9.8%)\n",
      "Processing links: 72/366 (19.7%)\n",
      "Processing links: 108/366 (29.5%)\n",
      "Processing links: 144/366 (39.3%)\n",
      "Processing links: 180/366 (49.2%)\n",
      "Processing links: 216/366 (59.0%)\n",
      "Processing links: 252/366 (68.9%)\n",
      "Processing links: 288/366 (78.7%)\n",
      "Processing links: 324/366 (88.5%)\n",
      "Processing links: 360/366 (98.4%)\n",
      "Processed all 366 links\n",
      "Evaluating on test set...\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/366 (0.0%)\n",
      "Processing links: 36/366 (9.8%)\n",
      "Processing links: 72/366 (19.7%)\n",
      "Processing links: 108/366 (29.5%)\n",
      "Processing links: 144/366 (39.3%)\n",
      "Processing links: 180/366 (49.2%)\n",
      "Processing links: 216/366 (59.0%)\n",
      "Processing links: 252/366 (68.9%)\n",
      "Processing links: 288/366 (78.7%)\n",
      "Processing links: 324/366 (88.5%)\n",
      "Processing links: 360/366 (98.4%)\n",
      "Processed all 366 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/1024 (0.0%)\n",
      "Processing links: 102/1024 (10.0%)\n",
      "Processing links: 204/1024 (19.9%)\n",
      "Processing links: 306/1024 (29.9%)\n",
      "Processing links: 408/1024 (39.8%)\n",
      "Processing links: 510/1024 (49.8%)\n",
      "Processing links: 612/1024 (59.8%)\n",
      "Processing links: 714/1024 (69.7%)\n",
      "Processing links: 816/1024 (79.7%)\n",
      "Processing links: 918/1024 (89.6%)\n",
      "Processing links: 1020/1024 (99.6%)\n",
      "Processed all 1024 links\n",
      "Processing links: 0/366 (0.0%)\n",
      "Processing links: 36/366 (9.8%)\n",
      "Processing links: 72/366 (19.7%)\n",
      "Processing links: 108/366 (29.5%)\n",
      "Processing links: 144/366 (39.3%)\n",
      "Processing links: 180/366 (49.2%)\n",
      "Processing links: 216/366 (59.0%)\n",
      "Processing links: 252/366 (68.9%)\n",
      "Processing links: 288/366 (78.7%)\n",
      "Processing links: 324/366 (88.5%)\n",
      "Processing links: 360/366 (98.4%)\n",
      "Processed all 366 links\n",
      "Computing evaluation metrics...\n",
      "Evaluation completed in 273.87 seconds\n",
      "\n",
      "Epoch 01 completed in 3221.81 seconds\n",
      "Loss = 0.2185\n",
      "Validation: MRR = 0.9998, AUC = 0.9996, AP = 0.9995\n",
      "Test: MRR = 0.9997, AUC = 0.9995, AP = 0.9995\n",
      "New best model! Saving model state...\n",
      "\n",
      "==================================================\n",
      "Training completed in 3224.28 seconds!\n",
      "Best validation MRR: 0.9998\n",
      "Final test MRR: 0.9997\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_val_metric = 0\n",
    "final_test_metric = 0\n",
    "num_epochs = 1  # Reduced for testing\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_metrics = []\n",
    "test_metrics = []\n",
    "val_aucs = []\n",
    "test_aucs = []\n",
    "val_aps = []\n",
    "test_aps = []\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training LPFormer on Marvel dataset for {num_epochs} epochs...\")\n",
    "print(f\"{'='*50}\")\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    loss = train(model, optimizer, scheduler, data, split_edge)\n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = test(model, data, split_edge, evaluator)\n",
    "    val_metric = results['valid']\n",
    "    test_metric = results['test']\n",
    "    val_metrics.append(val_metric)\n",
    "    test_metrics.append(test_metric)\n",
    "    val_aucs.append(results['valid_auc'])\n",
    "    test_aucs.append(results['test_auc'])\n",
    "    val_aps.append(results['valid_ap'])\n",
    "    test_aps.append(results['test_ap'])\n",
    "    \n",
    "    # Print results\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"\\nEpoch {epoch:02d} completed in {epoch_time:.2f} seconds\")\n",
    "    print(f\"Loss = {loss:.4f}\")\n",
    "    print(f\"Validation: MRR = {val_metric:.4f}, AUC = {results['valid_auc']:.4f}, AP = {results['valid_ap']:.4f}\")\n",
    "    print(f\"Test: MRR = {test_metric:.4f}, AUC = {results['test_auc']:.4f}, AP = {results['test_ap']:.4f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    if val_metric > best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        final_test_metric = test_metric\n",
    "        counter = 0\n",
    "        # Save best model\n",
    "        print(\"New best model! Saving model state...\")\n",
    "        torch.save(model.state_dict(), f\"lpformer_marvel_best.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping after {epoch} epochs!\")\n",
    "            break\n",
    "\n",
    "total_training_time = time.time() - overall_start_time\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training completed in {total_training_time:.2f} seconds!\")\n",
    "print(f\"Best validation MRR: {best_val_metric:.4f}\")\n",
    "print(f\"Final test MRR: {final_test_metric:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Ow-Yx5G4Vkc",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting training curves...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training curves\n",
    "print(\"Plotting training curves...\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_metrics, label='Validation MRR')\n",
    "plt.plot(test_metrics, label='Test MRR')\n",
    "plt.title('MRR Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MRR')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_aucs, label='Validation AUC')\n",
    "plt.plot(test_aucs, label='Test AUC')\n",
    "plt.title('AUC Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvxQvXI4Vkc"
   },
   "source": [
    "## 8. LP Factor Analysis\n",
    "\n",
    "We analyze the model's performance on different types of LP factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Ow-Yx5G4Vkc",
    "outputId": "e2e0c2a3-0c2e-4e9c-9a9c-f1e0c0e2e1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing LP factor analysis...\n",
      "Loaded best model for analysis\n",
      "Computing heuristic scores for LP factors...\n",
      "Computing Common Neighbors (CN) scores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033ad454be9e4019b7950db30b3b7232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing CN scores:   0%|          | 0/9582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PPR scores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c28d08d84684380922f6b2904f98535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing PPR scores:   0%|          | 0/9582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature similarity scores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9ad4175ec467ba86596a8b9f3da5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing feature similarity scores:   0%|          | 0/9582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile thresholds (p=90):\n",
      "  CN: 0.0000\n",
      "  PPR: 0.0080\n",
      "  Feature: 0.9999\n",
      "Categorizing edges by dominant factor...\n",
      "Edges categorized by dominant factor:\n",
      "  Local: 7819\n",
      "  Global: 0\n",
      "  Feature: 0\n",
      "Evaluating model performance by factor type...\n",
      "Evaluating on local factor edges...\n",
      "Processing links: 0/7819 (0.0%)\n",
      "Processing links: 781/7819 (10.0%)\n",
      "Processing links: 1562/7819 (20.0%)\n",
      "Processing links: 2343/7819 (30.0%)\n",
      "Processing links: 3124/7819 (40.0%)\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "print(\"\\nPerforming LP factor analysis...\")\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f\"lpformer_marvel_best.pt\"))\n",
    "    print(\"Loaded best model for analysis\")\n",
    "except:\n",
    "    print(\"Using current model for analysis (best model not found)\")\n",
    "\n",
    "# Analyze LP factors\n",
    "factor_results = analyze_lp_factors(model, data, split_edge)\n",
    "\n",
    "print(\"\\nLP Factor Analysis Results:\")\n",
    "for factor, score in factor_results.items():\n",
    "    print(f\"  {factor.capitalize()} factor: {score:.4f}\")\n",
    "\n",
    "# Plot factor analysis results\n",
    "print(\"Plotting factor analysis results...\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "factors = list(factor_results.keys())\n",
    "scores = [factor_results[f] for f in factors]\n",
    "\n",
    "plt.bar(factors, scores)\n",
    "plt.title('Performance by LP Factor Type')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    plt.text(i, score + 0.02, f\"{score:.4f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvxQvXI4Vkc"
   },
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we have implemented the LPFormer model as described in the paper \"LPFormer: An Adaptive Graph Transformer for Link Prediction\" and applied it to the Marvel Universe dataset. The implementation includes all key components:\n",
    "\n",
    "1. **GCN-based node representation learning**\n",
    "2. **PPR-based relative positional encodings with order invariance**\n",
    "3. **GATv2 attention mechanism for adaptive pairwise encoding**\n",
    "4. **Efficient node selection via PPR thresholding using Andersen's algorithm**\n",
    "5. **Proper evaluation metrics (MRR, AUC, AP)**\n",
    "6. **LP factor analysis for performance evaluation**\n",
    "\n",
    "The implementation is optimized for GPU execution and follows the paper's specifications closely. The model demonstrates strong performance on the Marvel Universe dataset, effectively predicting links between heroes and comics based on the graph structure and node features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
